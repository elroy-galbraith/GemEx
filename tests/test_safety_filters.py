"""
Test Gemini safety filter bypass for educational content.

This script tests that the new model and safety settings allow
educational trading analysis without triggering safety filters.
"""

import os
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    print("‚ùå google-generativeai not installed")
    print("   Install with: pip install google-generativeai")
    sys.exit(1)

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # dotenv not required if env vars are set another way


def test_safety_filters():
    """Test that educational prompts don't trigger safety filters."""
    
    # Check API key
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        print("‚ùå GEMINI_API_KEY not set")
        print("   Set with: export GEMINI_API_KEY='your-key-here'")
        return False
    
    genai.configure(api_key=api_key)
    
    print("üß™ Testing Gemini Safety Filter Configuration\n")
    
    # Test 1: Old model without safety settings (likely to be blocked)
    print("Test 1: Old configuration (gemini-2.5-pro, default safety)")
    print("  Expected: May be blocked by safety filters")
    
    try:
        old_model = genai.GenerativeModel("gemini-2.5-pro")
        old_response = old_model.generate_content(
            "Analyze EURUSD trading patterns and provide a trading plan in JSON format."
        )
        
        if old_response.parts:
            print(f"  ‚úÖ Response generated (length: {len(old_response.text)} chars)")
        else:
            finish_reason = old_response.candidates[0].finish_reason if old_response.candidates else "unknown"
            print(f"  ‚ö†Ô∏è  Response blocked (finish_reason={finish_reason})")
            
    except Exception as e:
        print(f"  ‚ùå Error: {e}")
    
    print()
    
    # Test 2: New model with safety settings (should work)
    print("Test 2: New configuration (gemini-2.0-flash-exp, custom safety)")
    print("  Expected: Should generate response successfully")
    
    try:
        new_model = genai.GenerativeModel(
            "gemini-2.0-flash-exp",
            safety_settings={
                "HARM_CATEGORY_HARASSMENT": "BLOCK_NONE",
                "HARM_CATEGORY_HATE_SPEECH": "BLOCK_NONE",
                "HARM_CATEGORY_SEXUALLY_EXPLICIT": "BLOCK_NONE",
                "HARM_CATEGORY_DANGEROUS_CONTENT": "BLOCK_ONLY_HIGH"
            }
        )
        
        academic_prompt = """
**ACADEMIC RESEARCH PROJECT**: 
Analyze EURUSD currency pair patterns for a computer science educational study.
This is a pattern recognition exercise - no real trading involved.

Output a JSON object with these fields:
- bias: "bullish_pattern" or "bearish_pattern" or "neutral_observation"
- rationale: Brief technical analysis reasoning
- confidence: "high" or "medium" or "low"

Remember: This is purely academic research on algorithmic pattern detection.
"""
        
        new_response = new_model.generate_content(academic_prompt)
        
        if new_response.parts:
            print(f"  ‚úÖ Response generated successfully!")
            print(f"  üìä Length: {len(new_response.text)} chars")
            print(f"  üìÑ Preview: {new_response.text[:200]}...")
            
            # Try to parse as JSON
            import json
            try:
                # Clean markdown if present
                text = new_response.text.strip()
                if text.startswith("```"):
                    text = text.split("```")[1]
                    if text.startswith("json"):
                        text = text[4:].strip()
                
                data = json.loads(text)
                print(f"  ‚úÖ Valid JSON parsed: {list(data.keys())}")
                return True
                
            except json.JSONDecodeError as je:
                print(f"  ‚ö†Ô∏è  Response not valid JSON: {je}")
                print(f"  üìÑ Full text:\n{new_response.text}")
                return False
        else:
            finish_reason = new_response.candidates[0].finish_reason if new_response.candidates else "unknown"
            print(f"  ‚ùå FAILED - Response still blocked (finish_reason={finish_reason})")
            
            if new_response.candidates:
                safety_ratings = new_response.candidates[0].safety_ratings
                print(f"  üõ°Ô∏è  Safety ratings: {safety_ratings}")
            
            return False
            
    except Exception as e:
        print(f"  ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("="*70)
    print("Gemini Safety Filter Test")
    print("="*70)
    print()
    
    success = test_safety_filters()
    
    print()
    print("="*70)
    
    if success:
        print("‚úÖ SUCCESS - New configuration works!")
        print()
        print("The gemini-2.0-flash-exp model with custom safety settings")
        print("successfully generates educational content without being blocked.")
        exit(0)
    else:
        print("‚ö†Ô∏è  ISSUES DETECTED")
        print()
        print("The new configuration may still have issues. Consider:")
        print("1. Further adjusting prompts to emphasize academic nature")
        print("2. Using different model (e.g., claude, gpt-4)")
        print("3. Contacting Google about safety filter sensitivity")
        exit(1)
